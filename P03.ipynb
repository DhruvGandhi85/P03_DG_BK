{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e59d02",
   "metadata": {},
   "source": [
    "## DS 4300 - Spring 2025\n",
    "Project Handout\n",
    "\n",
    "## Due: Friday April 18 @ 11:59 pm\n",
    "\n",
    "This project can be done in teams of two to four students. \n",
    "\n",
    "## Overview:\n",
    "Over the last few weeks, we have explored several AWS services, including:\n",
    "1. S3 for object storage\n",
    "2. EC2 for compute\n",
    "3. RDS for relational database access\n",
    "4. Lambda for serverless or ‚Äúon demand‚Äù computing\n",
    "\n",
    "In this project, you will create a simple ETL pipeline using the compute and storage services we have covered, in addition to any other services from the AWS Free Tier you would like to explore as a team.  \n",
    "\n",
    "The pipeline should have the following features:\n",
    "1. Accept ‚Äúuser‚Äù uploaded data through a UI or programmatic mock user. \n",
    "2. Automatically extract the data as uploaded and preprocess it through relevant processes to the data‚Äôs context (deal with missing values, pre-process an image, etc.  for example).  \n",
    "3. Store the data in its pre-processed form either in S3 (a different bucket than before) or an RDS database.  \n",
    "4. That storage should trigger some additional processing step(s) and subsequently store in an analysis-ready form.  \n",
    "\n",
    "Your project should also have a very simple web interface that shows some type of analytics of the data your users have uploaded.  The UI should run on an EC2 instance.  You can implement it using some package like Streamlit or another similar library or tool.  \n",
    "\n",
    "Your project must use the 4 AWS services we have covered in class. \n",
    "\n",
    "## Example Pipeline:\n",
    "(You cannot do this as a project, FYI.)\n",
    "\n",
    "1. Implement a web app running on EC2 using Streamlit \n",
    "2. The web app, among other features, allows users to upload image files to S3.  \n",
    "     - The app also allows users to enter additional information about the image that will be stored in a MySQL RDS database instance\n",
    "3. When the new image file is loaded into S3, a Lambda is triggered that sanitizes the image file (removes geotags, etc.) and generates 3 different resolutions of the image: one for phone, one for tablet, and one for desktop\n",
    "4. These 3 new images are written back to a different S3 bucket (it must be different than the source bucket), and their URLs are stored in the RDS instance. \n",
    "\n",
    "## Submission:\n",
    "\n",
    "You‚Äôll submit the following:\n",
    "1. A short slide deck in PDF (6-8 slides) detailing the following:\n",
    "     - Overview of your pipeline and main goals it should have achieved, including information about the source data sets\n",
    "     - The architecture of your data pipeline in diagram form\n",
    "     - Briefly explain how you used each AWS service and why you chose a particular service for a certain task service for that task\n",
    "     - An overview of what topics/skills you had to research to put your pipeline into full execution\n",
    "2. A short  4-5 minute video of your team explaining your pipeline and demoing the functionality.  It should be comprehensive enough for the viewer to see the state changes to the various services and data stores as the overall pipeline functions. \n",
    "     - Put a link to your demo video prominently on the first slide of your slide deck. \n",
    "     - All team members must appear in the demo video with camera on and participate substantively. \n",
    "\n",
    "## Creativity:\n",
    "\n",
    "Use this project as an opportunity to build something creative that you might want to show to future employers.  I‚Äôm giving you all a ton of leeway regarding what you build.  So, build something that satisfies the requirements while also could help you get a job üôÇ\n",
    "\n",
    "## Submission:\n",
    "\n",
    "You‚Äôll submit the PDF report (that includes a link to your demo video) to GradeScope. \n",
    "\n",
    "\n",
    "## Grading:\n",
    "- Creation of a functional AWS pipeline using required services (40%)\n",
    "- Report (30%)\n",
    "- Demo Video (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c071f7",
   "metadata": {},
   "source": [
    "# S3 JSON Uploader\n",
    "\n",
    "A Python CLI application that randomly selects and uploads JSON files from a specified folder to an AWS S3 bucket at regular intervals.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.11\n",
    "- AWS account with S3 access\n",
    "- Required Python packages (see requirements.txt)\n",
    "\n",
    "## AWS Setup Instructions\n",
    "\n",
    "### 1. Create S3 Bucket\n",
    "\n",
    "1. Log into AWS Management Console\n",
    "2. Navigate to S3 service\n",
    "3. Make sure you're in the correct AWS Region\n",
    "4. Click \"Create bucket\"\n",
    "5. Configure bucket settings:\n",
    "   - Choose `General purpose` bucket type\n",
    "   - Choose a globally unique bucket name (this will be your `S3_BUCKET_NAME` in .env)\n",
    "   - Leave most settings as default\n",
    "   - Click \"Create bucket\"\n",
    "\n",
    "### 2. Create IAM User and Policy\n",
    "\n",
    "1. Go to IAM service in AWS Console\n",
    "2. Click \"Users\" ‚Üí \"Create user\"\n",
    "3. Give your user a name (e.g., \"s3-uploader\")\n",
    "4. Do NOT check the box next to \"Provide user access to the AWS Management Console\"\n",
    "5. Click \"Next: Permissions\"\n",
    "6. Click \"Attach policies directly\"\n",
    "7. Create a new policy (Button in Policy section)\n",
    "8. On the next page, choose JSON in the Policy Editor\n",
    "9. Copy and paste the following\n",
    "   ```json\n",
    "   {\n",
    "     \"Version\": \"2012-10-17\",\n",
    "     \"Statement\": [\n",
    "       {\n",
    "         \"Effect\": \"Allow\",\n",
    "         \"Action\": [\"s3:PutObject\", \"s3:GetObject\", \"s3:ListBucket\"],\n",
    "         \"Resource\": [\n",
    "           \"arn:aws:s3:::ds4300bucket01\",\n",
    "           \"arn:aws:s3:::ds4300bucket01/*\"\n",
    "         ]\n",
    "       }\n",
    "     ]\n",
    "   }\n",
    "   ```\n",
    "   (Replace `YOUR-BUCKET-NAME` with your actual bucket name)\n",
    "10. Give the policy a name (e.g., \"S3UploadAccess\")\n",
    "11. Attach this policy to your user\n",
    "12. Complete the user creation\n",
    "13. **IMPORTANT**: Save the Access Key ID and Secret Access Key - these are your credentials for the .env file\n",
    "\n",
    "## Project Setup\n",
    "\n",
    "1. Clone this repository\n",
    "2. Install dependencies:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. Copy `.env.example` to `.env` and fill in your AWS credentials:\n",
    "   ```bash\n",
    "   cp .env.example .env\n",
    "   ```\n",
    "4. Edit the `.env` file with your AWS credentials:\n",
    "   ```\n",
    "   AWS_ACCESS_KEY_ID=your_access_key_here\n",
    "   AWS_SECRET_ACCESS_KEY=your_secret_key_here\n",
    "   AWS_REGION=your_aws_region\n",
    "   S3_BUCKET_NAME=your_bucket_name\n",
    "   ```\n",
    "5. Update the configuration variables in `src/s3_uploader.py`:\n",
    "   - `DATA_FOLDER`: Path to your JSON files\n",
    "   - `UPLOAD_INTERVAL`: Time between uploads in seconds\n",
    "\n",
    "## Usage\n",
    "\n",
    "Run the script:\n",
    "\n",
    "```bash\n",
    "python src/s3_uploader.py\n",
    "```\n",
    "\n",
    "The script will:\n",
    "\n",
    "1. Load AWS credentials from the .env file\n",
    "2. Connect to your S3 bucket\n",
    "3. Randomly select a JSON file from the specified folder\n",
    "4. Upload it to the S3 bucket\n",
    "5. Wait for the specified interval\n",
    "6. Repeat the process\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    ".\n",
    "‚îú‚îÄ‚îÄ data-news-articles/     # Folder containing JSON files to upload\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ s3_uploader.py     # Main script\n",
    "‚îú‚îÄ‚îÄ .env                   # AWS credentials (not in version control)\n",
    "‚îú‚îÄ‚îÄ .env.example          # Template for .env file\n",
    "‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies\n",
    "‚îî‚îÄ‚îÄ README.md            # This file\n",
    "```\n",
    "\n",
    "## Security Notes\n",
    "\n",
    "- Never commit your `.env` file to version control\n",
    "- Keep your AWS credentials secure\n",
    "- Use appropriate IAM roles and permissions for S3 access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ‚ÄúFitTrack‚Äù ‚Äì A Fitness Progress Tracker with Image + Data Uploads\n",
    "# Overview:\n",
    "# Users upload progress photos and log fitness data (e.g., weight, workouts, meals). The app processes images, cleans fitness logs, and visualizes progress.\n",
    "\n",
    "# Pipeline:\n",
    "\n",
    "# EC2 + Streamlit: User uploads images and fitness data (CSV or form input).\n",
    "\n",
    "# S3 (Raw): Uploaded images stored in an S3 bucket.\n",
    "\n",
    "# Lambda: Triggered on new image ‚Üí strips metadata, resizes for thumbnails and dashboards ‚Üí stores in a new S3 bucket.\n",
    "\n",
    "# RDS: Stores user input logs and URLs of processed images.\n",
    "\n",
    "# Analytics UI: Shows progress graphs, calories burned, workout frequency, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a15502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.110.135.169:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "\u001b[31m‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/Documents/DS 4300/P03_DG_BK-main/src/\u001b[0m\u001b[1;33ms3_uploader.py\u001b[0m:\u001b[94m37\u001b[0m in         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[92mupload_to_s3\u001b[0m                                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0ms3_client.upload_fileobj(                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mfile, bucket_name, \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33muploads/\u001b[0m\u001b[33m{\u001b[0mPath(file_path).name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m37 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSuccessfully uploaded \u001b[0m\u001b[33m{\u001b[0mfile_path.name\u001b[33m}\u001b[0m\u001b[33m to S3\u001b[0m\u001b[33m\"\u001b[0m)                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mError uploading \u001b[0m\u001b[33m{\u001b[0m\u001b[1;4mfile_path.name\u001b[0m\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m{\u001b[0m\u001b[96mstr\u001b[0m(e)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m40 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n",
      "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'str'\u001b[0m object has no attribute \u001b[32m'name'\u001b[0m\n",
      "\n",
      "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "\u001b[31m‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/anaconda3/envs/practicals/lib/python3.11/site-packages/streamlit/\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33mruntime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m:\u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/anaconda3/envs/practicals/lib/python3.11/site-packages/streamlit/\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33mruntime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner.py\u001b[0m:\u001b[94m640\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/Documents/DS 4300/P03_DG_BK-main/src/\u001b[0m\u001b[1;33mstreamlit_app.py\u001b[0m:\u001b[94m19\u001b[0m in       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[92m<module>\u001b[0m                                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(image.name, \u001b[33m\"\u001b[0m\u001b[33mwb\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m f:                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mf.write(image.getbuffer())                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m‚îÇ   \u001b[0ms3_uploader.main(image.name)                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m19 \u001b[2m‚îÇ   \u001b[0m\u001b[1;4mst.success(\u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mImage \u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mimage.name\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m uploa\u001b[0m\u001b[33mded!\u001b[0m\u001b[33m\"\u001b[0m)                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m20 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m# Fitness Data\u001b[0m                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m22 \u001b[0mst.subheader(\u001b[33m\"\u001b[0m\u001b[33mLog Your Fitness Data\u001b[0m\u001b[33m\"\u001b[0m)                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/Documents/DS 4300/P03_DG_BK-main/src/\u001b[0m\u001b[1;33ms3_uploader.py\u001b[0m:\u001b[94m64\u001b[0m in \u001b[92mmain\u001b[0m    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m61 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mregion_name=aws_credentials[\u001b[33m\"\u001b[0m\u001b[33maws_region\u001b[0m\u001b[33m\"\u001b[0m],                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m62 \u001b[0m\u001b[2m‚îÇ   \u001b[0m)                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m63 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m64 \u001b[2m‚îÇ   \u001b[0m\u001b[1;4mupload_to_s3(s3_client, file_path, aws_credentials[\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33ms3_bucket_name\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m])\u001b[0m       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m65 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m66 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m67 \u001b[0m\u001b[2m‚îÇ   \u001b[0mmain()                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2;33m/Users/dhruvgandhi/Documents/DS 4300/P03_DG_BK-main/src/\u001b[0m\u001b[1;33ms3_uploader.py\u001b[0m:\u001b[94m39\u001b[0m in         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[92mupload_to_s3\u001b[0m                                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSuccessfully uploaded \u001b[0m\u001b[33m{\u001b[0mfile_path.name\u001b[33m}\u001b[0m\u001b[33m to S3\u001b[0m\u001b[33m\"\u001b[0m)                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m‚ù± \u001b[0m39 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mError uploading \u001b[0m\u001b[33m{\u001b[0m\u001b[1;4mfile_path.name\u001b[0m\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m{\u001b[0m\u001b[96mstr\u001b[0m(e)\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m40 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m41 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m42 \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mmain\u001b[0m(file_path):                                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n",
      "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'str'\u001b[0m object has no attribute \u001b[32m'name'\u001b[0m\n",
      "Successfully uploaded temp_image.jpeg to S3\n",
      "Successfully uploaded temp_image.jpeg to S3\n",
      "Successfully uploaded temp_image.jpeg to S3\n",
      "Successfully uploaded temp_image.jpeg to S3\n",
      "Successfully uploaded temp_image.jpeg to S3\n",
      "Successfully uploaded temp_fitness_data.json to S3\n"
     ]
    }
   ],
   "source": [
    "!streamlit run src/streamlit_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791a836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
